{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **CMPE 258 Assignment 02 - Part A: Tokenization**\n",
        "---\n",
        "\n",
        "**Author:** *Suresh Ravuri*\n",
        "\n",
        "#### **Assignment Description:**\n",
        "\n",
        "The assignment focuses on replicating and extending experiments with Language Model Models (LLMs) using different datasets from Hugging Face. The goal is to showcase adaptability and creativity in applying LLMs.\n",
        "\n",
        "#### **Tasks:**\n",
        "\n",
        "1. **Experiment Replication:** Replicate experiments from provided YouTube videos covering various aspects such as prompt-based generation, fine-tuning, Retrieval-Augmented Generation (RAG), local interpreter, function calling, and llama.cpp CPU inference.\n",
        "\n",
        "2. **Creative Adaptation:** Adapt Colab notebooks to highlight innovative LLM use cases and applications.\n",
        "\n",
        "3. **Notebook Adjustments:** Make necessary modifications to Colab notebooks to ensure correct functionality, documenting these changes thoroughly.\n",
        "\n",
        "4. **Demonstration Video:** Produce a demonstration video illustrating modified Colab notebooks' functionality and innovative use cases, with the video linked in the documentation.\n",
        "\n",
        "#### **Additional Instructions:**\n",
        "\n",
        "\n",
        "1. [A Hackers' Guide to Language Models:](https://www.youtube.com/watch?v=jkrNMKz9pWU) This video showcases various experiments using LLMs.\n",
        "2. [A hacker's guide to open source LLMs - posit::conf(2023):](https://www.youtube.com/watch?v=sYliwvml9Es) This video provides additional insights into LLMs.\n",
        "3. [Summary of A Hackers' Guide to Language Models:](https://www.summarize.tech/www.youtube.com/watch?v=jkrNMKz9pWU) Summarized version video titled \"A Hackers' Guide to Language Models\".\n",
        "4. [Summary of A hacker's guide to open source LLMs - posit::conf(2023):](https://www.summarize.tech/www.youtube.com/watch?v=sYliwvml9Es) Summarized version of video titled \"Summary of A hacker's guide to open source LLMs - posit::conf(2023)\".\n",
        "5. [Hugging Face Datasets:](https://huggingface.co/knowrohit07) Alternative datasets for experiments.\n"
      ],
      "metadata": {
        "id": "sxd2Xbwoqcmn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization**"
      ],
      "metadata": {
        "id": "5nlEwzyLs7_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSg_Ry7MtEbg",
        "outputId": "f636fd2d-c9e1-4ab7-b873-a8451b30db8a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tiktoken import encoding_for_model\n",
        "\n",
        "enc = encoding_for_model(\"text-davinci-003\")\n",
        "toks = enc.encode(\"This weekend, let's explore the latest advancements in quantum computing at the tech conference\")\n",
        "toks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJOnkgSltZMk",
        "outputId": "a368192b-fd75-4246-a3da-cca2f24a66d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1212,\n",
              " 5041,\n",
              " 11,\n",
              " 1309,\n",
              " 338,\n",
              " 7301,\n",
              " 262,\n",
              " 3452,\n",
              " 47220,\n",
              " 287,\n",
              " 14821,\n",
              " 14492,\n",
              " 379,\n",
              " 262,\n",
              " 7261,\n",
              " 4495]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[enc.decode_single_token_bytes(o).decode('utf-8') for o in toks]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEeuq75Ltnvj",
        "outputId": "9e008425-b2f1-4e31-a51a-585b8d965316"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " ' weekend',\n",
              " ',',\n",
              " ' let',\n",
              " \"'s\",\n",
              " ' explore',\n",
              " ' the',\n",
              " ' latest',\n",
              " ' advancements',\n",
              " ' in',\n",
              " ' quantum',\n",
              " ' computing',\n",
              " ' at',\n",
              " ' the',\n",
              " ' tech',\n",
              " ' conference']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}